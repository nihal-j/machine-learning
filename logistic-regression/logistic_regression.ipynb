{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, method='min-max'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes statistics assuming each sample is a row.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (method == 'min-max'):\n",
    "        numerator = data - np.min(data, axis=0)\n",
    "        denominator = np.max(data, axis=0) - np.min(data, axis=0)\n",
    "        return numerator/denominator\n",
    "    \n",
    "    if (method == 'standardization'):\n",
    "        numerator = data - np.mean(data, axis=0)\n",
    "        denominator = np.std(data, axis=0)\n",
    "        return numerator/denominator\n",
    "    \n",
    "def segregate_target(data):\n",
    "    \n",
    "    X = data[:, :-1]\n",
    "    t = data[:, -1:]\n",
    "    \n",
    "    return X, t\n",
    "\n",
    "def train_test_validation_split(X, t, test_ratio=0.33):\n",
    "    \n",
    "    X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=test_ratio, random_state=42)\n",
    "    X_valid, X_test, t_valid, t_test = train_test_split(X_test, t_test, test_size=0.5, random_state=42)\n",
    "    \n",
    "    data = {\n",
    "        'X_train': X_train,\n",
    "        't_train': t_train,\n",
    "        'X_valid': X_valid,\n",
    "        't_valid': t_valid,\n",
    "        'X_test': X_test,\n",
    "        't_test': t_test\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_data(path):\n",
    "    \n",
    "    data = np.load(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, random_init=True, maxIters=10000):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_init = random_init\n",
    "        self.maxIters = maxIters\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    \n",
    "    def initalize_parameters(self, dims):\n",
    "        \n",
    "        if self.random_init:\n",
    "            self.w = np.random.randn(dims).reshape(-1, 1)\n",
    "        else:\n",
    "            self.w = np.zeros((dims, 1))\n",
    "        self.b = 0\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \n",
    "        M = x.shape[1]\n",
    "        x[x > 15] = 15\n",
    "        x[x < -15] = -15\n",
    "            \n",
    "        return (1 / (1 + np.exp(-x)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        M = X.shape[1]\n",
    "        preds = np.zeros((1, M))\n",
    "        \n",
    "        probabilities = self.sigmoid(np.dot(self.w.T, X) + self.b)\n",
    "        \n",
    "        for i in range(M):\n",
    "            preds[0][i] = 0 if probabilities[0][i] <= 0.5 else 1\n",
    "            \n",
    "        return preds\n",
    "    \n",
    "    def calculate_accuracy(self, y, t):\n",
    "        \n",
    "        return 100 - (np.mean(np.abs(y - t))*100)\n",
    "        \n",
    "    \n",
    "    def fit(self, X_train, t_train):\n",
    "        \n",
    "        # number of features\n",
    "        N = X_train.shape[0]\n",
    "        # number of samples\n",
    "        M = X_train.shape[1]\n",
    "        \n",
    "        self.initalize_parameters(N)\n",
    "        costs = []\n",
    "        \n",
    "        for iteration in range(self.maxIters - 1):\n",
    "            \n",
    "            # forward calculation\n",
    "            y = self.sigmoid(np.dot(self.w.T, X_train) + self.b)\n",
    "            \n",
    "            # cost calculation\n",
    "            cost = -np.sum((t_train*np.log(y)) + ((1 - t_train)*np.log((1 - y))))\n",
    "            costs.append(cost)\n",
    "            \n",
    "            # gradient calculation\n",
    "            dw = np.dot(X_train, (y - t_train).T)\n",
    "            db = np.sum(y - t_train)\n",
    "            \n",
    "            # backward update\n",
    "            self.w = self.w - self.learning_rate*dw\n",
    "            self.b = self.b - self.learning_rate*db\n",
    "            \n",
    "        predictions = self.predict(X_train)\n",
    "        train_accuracy = self.calculate_accuracy(predictions, t_train)\n",
    "        print('Training accuracy is: ', train_accuracy)\n",
    "        \n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is:  99.34711643090316\n",
      "Testing accuracy is:  90.30837004405286\n"
     ]
    }
   ],
   "source": [
    "path = 'data/data.npy'\n",
    "data = load_data(path)\n",
    "\n",
    "# from here each sample is a row\n",
    "X, t = segregate_target(data)\n",
    "data = train_test_validation_split(X, t, test_ratio=0.33)\n",
    "\n",
    "data['X_train'] = normalize(data['X_train'])\n",
    "data['X_valid'] = normalize(data['X_valid'])\n",
    "data['X_test'] = normalize(data['X_test'])\n",
    "\n",
    "# from here each sample is a column\n",
    "X_train = data['X_train'].T\n",
    "t_train = data['t_train'].reshape(1,-1)\n",
    "X_test = data['X_test'].T\n",
    "t_test = data['t_test'].reshape(1,-1)\n",
    "\n",
    "model = Model(learning_rate=1.5, random_init=False, maxIters=100000)\n",
    "costs = model.fit(X_train, t_train)\n",
    "preds = model.predict(X_test)\n",
    "test_accuracy = model.calculate_accuracy(preds, t_test)\n",
    "print('Testing accuracy is: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is:  97.34513274336283\n"
     ]
    }
   ],
   "source": [
    "X_val = data['X_valid'].T\n",
    "t_val = data['t_valid'].T\n",
    "preds = model.predict(X_val)t\n",
    "val_accuracy = model.calculate_accuracy(preds, t_val)\n",
    "print('Validation accuracy is: ', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = np.array([[1.2, 1.4, 1.1], [-2.3, -1.6, -1.5]])\\nt_train = np.array([[1, 0, 1]])\\nX_test = np.array([[1.3], [-1.8]])\\nt_test = np.array([[0]])\\n\\nmodel = Model(maxIters=2)\\nmodel.fit(X_train, t_train)\\n'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X_train = np.array([[1.2, 1.4, 1.1], [-2.3, -1.6, -1.5]])\n",
    "t_train = np.array([[1, 0, 1]])\n",
    "X_test = np.array([[1.3], [-1.8]])\n",
    "t_test = np.array([[0]])\n",
    "\n",
    "model = Model(maxIters=2)\n",
    "model.fit(X_train, t_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
